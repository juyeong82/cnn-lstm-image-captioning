# ğŸ–¼ï¸ CNN-LSTM Image Captioning with PyTorch

**ì´ë¯¸ì§€ë¥¼ ì´í•´í•˜ê³  ìì—°ì–´ë¡œ ì„¤ëª…í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸**  
ResNet-152 CNN Encoderì™€ LSTM Decoderë¥¼ ê²°í•©í•œ ì´ë¯¸ì§€ ìº¡ì…”ë‹ ì‹œìŠ¤í…œ

---

## ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” **Encoder-Decoder ì•„í‚¤í…ì²˜**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ ë‚´ìš©ì„ ìë™ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ” ìì—°ì–´ ë¬¸ì¥ì„ ìƒì„±í•©ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•
- **CNN ì¸ì½”ë”**: ImageNetìœ¼ë¡œ ì‚¬ì „ í•™ìŠµëœ ResNet-152ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
- **LSTM ë””ì½”ë”**: ìˆœí™˜ ì‹ ê²½ë§ìœ¼ë¡œ ë¬¸ë§¥ì„ ê³ ë ¤í•œ ë‹¨ì–´ ì‹œí€€ìŠ¤ ìƒì„±
- **COCO ë°ì´í„°ì…‹**: ì•½ 41ë§Œ ê°œì˜ ì´ë¯¸ì§€-ìº¡ì…˜ ìŒìœ¼ë¡œ í•™ìŠµ
- **Teacher Forcing**: íš¨ìœ¨ì ì¸ í•™ìŠµì„ ìœ„í•œ ì •ë‹µ ê¸°ë°˜ í•™ìŠµ ì „ëµ
- **Greedy Search**: ì¶”ë¡  ì‹œ ë‹¨ê³„ë³„ ìµœì  ë‹¨ì–´ ì„ íƒ

---

## ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜

```

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚   ì…ë ¥ ì´ë¯¸ì§€  â”‚  â†’  â”‚  CNN Encoder â”‚  â†’  â”‚ íŠ¹ì§• ë²¡í„°(256D) â”‚

â”‚ (224Ã—224Ã—3) â”‚      â”‚ (ResNet-152) â”‚      â”‚                â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚ LSTM Decoder   â”‚

â”‚ (Hidden: 512D) â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚ ìƒì„±ëœ ìº¡ì…˜      â”‚

â”‚ "A dog playing"â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

### ë°ì´í„° íë¦„ (batch_size=128 ê¸°ì¤€)
1. **ì´ë¯¸ì§€ ì…ë ¥**: `(128, 3, 224, 224)`
2. **CNN íŠ¹ì§• ì¶”ì¶œ**: `(128, 2048)` â†’ Linear â†’ `(128, 256)`
3. **LSTM ì…ë ¥**: ì´ë¯¸ì§€ ë²¡í„° + ë‹¨ì–´ ì„ë² ë”© â†’ `(128, seq_len, 256)`
4. **ë‹¨ì–´ ì˜ˆì¸¡**: `(total_words, vocab_size)` â†’ Softmax â†’ ë‹¤ìŒ ë‹¨ì–´ ì„ íƒ

---

## ğŸ“Š í•™ìŠµ ê²°ê³¼

### ì„±ëŠ¥ ì§€í‘œ
- **ìµœì¢… Loss**: 2.1087
- **Perplexity**: 8.2372
- **í•™ìŠµ Epoch**: 2 epochs
- **ë°°ì¹˜ í¬ê¸°**: 128
- **Vocabulary Size**: 9,948ê°œ ë‹¨ì–´

### ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ

<div style="text-align: center;">
    <h3>Image 1</h3>
    <img src="results/sample_predictions/sample1.png" alt="Generated Caption Example 1" style="width: 80%; max-width: 600px; display: block; margin: 0 auto; border: 1px solid #ddd; border-radius: 4px; padding: 5px;">
    <p style="font-size: 1.2em; font-weight: bold; color: #333; margin-top: 10px;">Generated Caption: a man in a kitchen preparing food in a kitchen.</p>
    <br>
</div>

<div style="text-align: center;">
    <h3>Image 2</h3>
    <img src="results/sample_predictions/sample2.png" alt="Generated Caption Example 2" style="width: 80%; max-width: 600px; display: block; margin: 0 auto; border: 1px solid #ddd; border-radius: 4px; padding: 5px;">
    <p style="font-size: 1.2em; font-weight: bold; color: #333; margin-top: 10px;">Generated Caption: a baseball player is swinging at a ball.</p>
    <br>
</div>

<div style="text-align: center;">
    <h3>Image 3</h3>
    <img src="results/sample_predictions/sample3.png" alt="Generated Caption Example 3" style="width: 80%; max-width: 600px; display: block; margin: 0 auto; border: 1px solid #ddd; border-radius: 4px; padding: 5px;">
    <p style="font-size: 1.2em; font-weight: bold; color: #333; margin-top: 10px;">Generated Caption: a man riding a skateboard up the side of a ramp.</p>
    <br>
</div>
---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```

# ë ˆí¬ì§€í† ë¦¬ í´ë¡ 

git clone https://github.com/juyeong82/cnn-lstm-image-captioning.git

cd cnn-lstm-image-captioning

# ê°€ìƒ í™˜ê²½ ìƒì„± (ê¶Œì¥)

python -m venv venv

source venv/bin/activate  # Windows: venvScriptsactivate

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

pip install -r requirements.txt

# NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ

python -c "import nltk; [nltk.download](http://nltk.download)('punkt')"

```

### 2. ë°ì´í„° ì¤€ë¹„

```

# COCO ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ (ì•½ 13GB)

mkdir -p data_dir

cd data_dir

# í•™ìŠµ ì´ë¯¸ì§€

wget http://images.cocodataset.org/zips/train2014.zip

unzip [train2014.zip](http://train2014.zip)

# Annotation íŒŒì¼

wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip

unzip annotations_[trainval2014.zip](http://trainval2014.zip)

cd ..

```

### 3. ë‹¨ì–´ ì‚¬ì „ êµ¬ì¶•

```

from src.utils import build_vocabulary, save_vocabulary

# ë‹¨ì–´ ì‚¬ì „ ìƒì„± (threshold=4: 4ë²ˆ ì´ìƒ ë“±ì¥í•œ ë‹¨ì–´ë§Œ í¬í•¨)

vocab = build_vocabulary(

'data_dir/annotations/captions_train2014.json',

threshold=4

)

# ì €ì¥

save_vocabulary(vocab, 'data_dir/vocabulary.pkl')

print(f"Vocabulary size: {len(vocab)}")  # ì•½ 9,948ê°œ ë‹¨ì–´

```

### 4. ëª¨ë¸ í•™ìŠµ

```

python src/[train.py](http://train.py)

```

í•™ìŠµ ì¤‘ ë¡œê·¸:
```

Epoch [0/5], Step [0/3236], Loss: 9.2052, Perplexity: 9948.82

Epoch [0/5], Step [10/3236], Loss: 5.7601, Perplexity: 317.36

...

Epoch [1/5], Step [3230/3236], Loss: 2.1087, Perplexity: 8.24

```

**ì²´í¬í¬ì¸íŠ¸ ì €ì¥**: 1000 ìŠ¤í…ë§ˆë‹¤ `models_dir/encoder-{epoch}-{step}.ckpt`, `decoder-{epoch}-{step}.ckpt` ì €ì¥

### 5. ìº¡ì…˜ ìƒì„± (ì¶”ë¡ )

```

python src/[evaluate.py](http://evaluate.py)

```

ë˜ëŠ” Python ì½”ë“œë¡œ:

```

from src.evaluate import generate_caption

from src.models import CNNModel, LSTMModel

from src.utils import load_vocabulary

import torch

from torchvision import transforms

# ì„¤ì •

device = torch.device('cuda' if [torch.cuda.is](http://torch.cuda.is)_available() else 'cpu')

transform = transforms.Compose([

transforms.ToTensor(),

transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))

])

# ë‹¨ì–´ ì‚¬ì „ ë¡œë“œ

vocab = load_vocabulary('data_dir/vocabulary.pkl')

# ëª¨ë¸ ë¡œë“œ

encoder = CNNModel(256).to(device)

decoder = LSTMModel(256, 512, len(vocab), 1).to(device)

encoder.load_state_dict(torch.load('models_dir/encoder-2-3000.ckpt'))

decoder.load_state_dict(torch.load('models_dir/decoder-2-3000.ckpt'))

# ìº¡ì…˜ ìƒì„±

caption = generate_caption(

'path/to/your/image.jpg',

encoder, decoder, vocab, device, transform

)

print(caption)

```

---

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

```

cnn-lstm-image-captioning/

â”œâ”€â”€ [README.md](http://README.md)                 # í”„ë¡œì íŠ¸ ì„¤ëª…ì„œ

â”œâ”€â”€ requirements.txt          # ì˜ì¡´ì„± íŒ¨í‚¤ì§€

â”œâ”€â”€ .gitignore               # Git ì œì™¸ íŒŒì¼

â”‚

â”œâ”€â”€ src/                     # ì†ŒìŠ¤ ì½”ë“œ

â”‚   â”œâ”€â”€ **init**.py          # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”

â”‚   â”œâ”€â”€ [models.py](http://models.py)            # CNNModel, LSTMModel ì •ì˜

â”‚   â”œâ”€â”€ [dataset.py](http://dataset.py)           # CustomCocoDataset, DataLoader

â”‚   â”œâ”€â”€ [train.py](http://train.py)             # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

â”‚   â”œâ”€â”€ [evaluate.py](http://evaluate.py)          # ì¶”ë¡  ë° í‰ê°€

â”‚   â””â”€â”€ [utils.py](http://utils.py)             # Vocab, ì´ë¯¸ì§€ ë¡œë”© ë“±

â”‚

â”œâ”€â”€ notebooks/               # Jupyter ë…¸íŠ¸ë¶

â”‚   â””â”€â”€ image_captioning_full.ipynb

â”‚

â”œâ”€â”€ data/                    # ë°ì´í„° í´ë” (.gitignore)

â”‚   â”œâ”€â”€ train2014/           # COCO í•™ìŠµ ì´ë¯¸ì§€

â”‚   â”œâ”€â”€ annotations/         # COCO annotation JSON

â”‚   â””â”€â”€ vocabulary.pkl       # êµ¬ì¶•ëœ ë‹¨ì–´ ì‚¬ì „

â”‚

â”œâ”€â”€ models/                  # í•™ìŠµëœ ëª¨ë¸ (.gitignore)

â”‚   â”œâ”€â”€ encoder-2-3000.ckpt  # ì¸ì½”ë” ê°€ì¤‘ì¹˜

â”‚   â””â”€â”€ decoder-2-3000.ckpt  # ë””ì½”ë” ê°€ì¤‘ì¹˜

â”‚

â””â”€â”€ results/                 # ê²°ê³¼ë¬¼

â”œâ”€â”€ sample_predictions/  # ì˜ˆì¸¡ ê²°ê³¼ ì´ë¯¸ì§€

â””â”€â”€ training_logs/       # í•™ìŠµ ë¡œê·¸

```

---

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

### ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
- **PyTorch 2.0+**: ëª¨ë¸ êµ¬í˜„ ë° í•™ìŠµ
- **torchvision**: ì‚¬ì „ í•™ìŠµëœ ResNet-152, ì´ë¯¸ì§€ ì „ì²˜ë¦¬

### ë°ì´í„° ì²˜ë¦¬
- **pycocotools**: COCO ë°ì´í„°ì…‹ ì²˜ë¦¬
- **NLTK**: ìì—°ì–´ í† í°í™” (punkt tokenizer)
- **Pillow**: ì´ë¯¸ì§€ ë¡œë”© ë° ë¦¬ì‚¬ì´ì¦ˆ

### ì‹œê°í™”
- **matplotlib**: ê²°ê³¼ ì‹œê°í™”

---

## ğŸ“ˆ í•µì‹¬ ê°œë…

### 1. Encoder-Decoder ì•„í‚¤í…ì²˜
- **ì¸ì½”ë” (CNN)**: ì´ë¯¸ì§€ â†’ ê³ ì • ê¸¸ì´ íŠ¹ì§• ë²¡í„° (256ì°¨ì›)ë¡œ ì••ì¶•
- **ë””ì½”ë” (LSTM)**: íŠ¹ì§• ë²¡í„° â†’ ë‹¨ì–´ ì‹œí€€ìŠ¤ë¡œ ë””ì½”ë”©


### 2. Teacher Forcing
í•™ìŠµ ì‹œ ì´ì „ ì˜ˆì¸¡ ë‹¨ì–´ê°€ ì•„ë‹Œ **ì •ë‹µ ë‹¨ì–´**ë¥¼ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ì†ë„ í–¥ìƒ:
```

# t=1: ì´ë¯¸ì§€ â†’ "A"

# t=2: "A" (ì •ë‹µ) â†’ "dog"

# t=3: "dog" (ì •ë‹µ) â†’ "playing"

```

### 3. Greedy Search (ì¶”ë¡  ì‹œ)
ê° ì‹œì ì—ì„œ **ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ë‹¨ì–´**ë¥¼ ì„ íƒí•˜ì—¬ ë¬¸ì¥ ìƒì„±:
```

for t in range(max_length):

logits = model(input_t)

word = argmax(logits)  # ìµœëŒ€ í™•ë¥  ë‹¨ì–´ ì„ íƒ

input_t+1 = embedding(word)

```

### 4. Pack Padded Sequence
ê°€ë³€ ê¸¸ì´ ìº¡ì…˜ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ íŒ¨ë”©ëœ ì‹œí€€ìŠ¤ë¥¼ ì••ì¶•:
```

packed = pack_padded_sequence(embeddings, lengths, batch_first=True)

```

---

## ğŸ”‘ ì£¼ìš” í´ë˜ìŠ¤ ë° í•¨ìˆ˜

### `src/[models.py](http://models.py)`

**CNNModel**
- `__init__(embedding_size)`: ResNet-152 ê¸°ë°˜ ì¸ì½”ë” ì´ˆê¸°í™”
- `forward(images)`: ì´ë¯¸ì§€ â†’ íŠ¹ì§• ë²¡í„° (256D) ë³€í™˜

**LSTMModel**
- `__init__(embed_size, hidden_size, vocab_size, num_layers)`: LSTM ë””ì½”ë” ì´ˆê¸°í™”
- `forward(features, captions, lengths)`: í•™ìŠµ ì‹œ ì‚¬ìš© (Teacher Forcing)
- `sample(features, states)`: ì¶”ë¡  ì‹œ ìº¡ì…˜ ìƒì„± (Greedy Search)

### `src/[dataset.py](http://dataset.py)`

**CustomCocoDataset**
- `__getitem__(idx)`: (ì´ë¯¸ì§€, ìº¡ì…˜) ìŒ ë°˜í™˜

**collate_function**
- ê°€ë³€ ê¸¸ì´ ìº¡ì…˜ì„ ë°°ì¹˜ë¡œ ë¬¶ê³  íŒ¨ë”© ì ìš©

**get_loader**
- DataLoader ìƒì„± í—¬í¼ í•¨ìˆ˜

### `src/[utils.py](http://utils.py)`

**Vocab**
- `add_token(token)`: ë‹¨ì–´ ì¶”ê°€
- `__call__(token)`: ë‹¨ì–´ â†’ ì¸ë±ìŠ¤ ë³€í™˜

**build_vocabulary**
- COCO JSONì—ì„œ ë‹¨ì–´ ì‚¬ì „ êµ¬ì¶•

**load_image**
- ì¶”ë¡ ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬

---


## ğŸ“ í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
```

# src/[train.py](http://train.py)ì˜ config ìˆ˜ì •

config = {

'embedding_size': 256,      # ì„ë² ë”© ì°¨ì› (256, 512 ê¶Œì¥)

'hidden_size': 512,         # LSTM hidden size (512, 1024 ê¶Œì¥)

'num_layers': 1,            # LSTM ë ˆì´ì–´ ìˆ˜

'learning_rate': 0.001,     # í•™ìŠµë¥  (0.001~0.0001)

'batch_size': 128,          # ë°°ì¹˜ í¬ê¸° (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •)

}

```

### GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ
- `batch_size` ì¤„ì´ê¸° (128 â†’ 64 â†’ 32)
- `num_workers` ì¤„ì´ê¸° (2 â†’ 0)
- ì´ë¯¸ì§€ í¬ê¸° ì¤„ì´ê¸° (224 â†’ 196)

---

## ğŸ‘¤ ì‘ì„±ì

**Juyeong Park**  
- Email: [ju0korea@korea.ac.kr](mailto:ju0korea@korea.ac.kr)
- GitHub: [@juyeong82](https://github.com/juyeong82)

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

---
