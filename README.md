# ğŸ–¼ï¸ CNN-LSTM Image Captioning with PyTorch

[![Python](https://img.shields.io/badge/Python-3.12.7-blue?logo=python)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.5.1-ee4c2c?logo=pytorch)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

> **ì‚¬ì§„ í•œ ì¥ë§Œ ë³´ì—¬ì£¼ë©´, AIê°€ ë¬¸ì¥ìœ¼ë¡œ ì‚¬ì§„ì„ ë¬˜ì‚¬í•©ë‹ˆë‹¤.**
>
> ì´ í”„ë¡œì íŠ¸ëŠ” ResNet-152 CNN Encoderì™€ LSTM Decoderë¥¼ ê²°í•©í•˜ì—¬ ì´ë¯¸ì§€ì˜ í•µì‹¬ ë‚´ìš©ì„ íŒŒì•…í•˜ê³  ìì—°ì–´ ìº¡ì…˜ì„ ìƒì„±í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

---
## 1. ìƒ˜í”Œ ì˜ˆì¸¡ ê²°ê³¼
---
### Image 1
![Generated Caption Example 1](results/sample_predictions/sample1.png)

---
### Image 2
![Generated Caption Example 2](results/sample_predictions/sample2.png)

---
### Image 3
![Generated Caption Example 3](results/sample_predictions/sample3.png)

---

## 2. í”„ë¡œì íŠ¸ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” **Encoder-Decoder ì•„í‚¤í…ì²˜**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ ë‚´ìš©ì„ ìë™ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ” ìì—°ì–´ ë¬¸ì¥ì„ ìƒì„±í•©ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•
- **CNN Encoder**: ì‚¬ì „ í•™ìŠµëœ **ResNet-152** ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ í’ë¶€í•œ ì‹œê°ì  íŠ¹ì§•(feature)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
- **lSTM Decoder**: ì¶”ì¶œëœ íŠ¹ì§• ë²¡í„°ë¥¼ ì´ˆê¸° ì…ë ¥ìœ¼ë¡œ ë°›ì•„, **LSTM ë„¤íŠ¸ì›Œí¬**ê°€ ë¬¸ë§¥ì— ë§ëŠ” ë‹¨ì–´ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
- **ëŒ€ê·œëª¨ ë°ì´í„°ì…‹**: **MS COCO 2014** ë°ì´í„°ì…‹ì˜ ì•½ 41ë§Œ ê°œ ì´ë¯¸ì§€-ìº¡ì…˜ ìŒì„ í†µí•´ í•™ìŠµí•˜ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.

---

### ë°ì´í„° íë¦„ (batch_size=128 ê¸°ì¤€)
1. **ì´ë¯¸ì§€ ì…ë ¥**: `(128, 3, 224, 224)`
2. **CNN íŠ¹ì§• ì¶”ì¶œ**: `(128, 2048)` â†’ Linear â†’ `(128, 256)`
3. **LSTM ì…ë ¥**: ì´ë¯¸ì§€ ë²¡í„° + ë‹¨ì–´ ì„ë² ë”© â†’ `(128, seq_len, 256)`
4. **ë‹¨ì–´ ì˜ˆì¸¡**: `(total_words, vocab_size)` â†’ Softmax â†’ ë‹¤ìŒ ë‹¨ì–´ ì„ íƒ

---

## 3. í•™ìŠµ ê²°ê³¼

### ì„±ëŠ¥ ì§€í‘œ
- **ìµœì¢… Loss**: 2.1087
- **Perplexity**: 8.2372
- **í•™ìŠµ Epoch**: 2 epochs
- **ë°°ì¹˜ í¬ê¸°**: 128
- **Vocabulary Size**: 9,948ê°œ ë‹¨ì–´

---

## 4. ì„¤ì¹˜ ë° ì‹¤í–‰ ë°©ë²•

### 1. í™˜ê²½ ì„¤ì •

```

# ë ˆí¬ì§€í† ë¦¬ í´ë¡ 

git clone https://github.com/juyeong82/cnn-lstm-image-captioning.git

cd cnn-lstm-image-captioning

# ê°€ìƒ í™˜ê²½ ìƒì„± (ê¶Œì¥)

python -m venv venv

source venv/bin/activate  # Windows: venvScriptsactivate

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

pip install -r requirements.txt

# NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ

python -c "import nltk; [nltk.download](http://nltk.download)('punkt')"

```

### 2. ë°ì´í„° ì¤€ë¹„

```

# COCO ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ (ì•½ 13GB)

mkdir -p data_dir

cd data_dir

# í•™ìŠµ ì´ë¯¸ì§€

wget http://images.cocodataset.org/zips/train2014.zip

unzip [train2014.zip](http://train2014.zip)

# Annotation íŒŒì¼

wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip

unzip annotations_[trainval2014.zip](http://trainval2014.zip)

cd ..

```

### 3. ë‹¨ì–´ ì‚¬ì „ êµ¬ì¶•

```

python src/[build_vocab.py]

```


### 4. ëª¨ë¸ í•™ìŠµ

```

python src/[train.py]

```

í•™ìŠµ ì¤‘ ë¡œê·¸:
```

Epoch [0/5], Step [0/3236], Loss: 9.2052, Perplexity: 9948.82

Epoch [0/5], Step [10/3236], Loss: 5.7601, Perplexity: 317.36

...

Epoch [1/5], Step [3230/3236], Loss: 2.1087, Perplexity: 8.24

```

**ì²´í¬í¬ì¸íŠ¸ ì €ì¥**: 1000 ìŠ¤í…ë§ˆë‹¤ `models_dir/encoder-{epoch}-{step}.ckpt`, `decoder-{epoch}-{step}.ckpt` ì €ì¥

### 5. ìº¡ì…˜ ìƒì„± (ì¶”ë¡ )

```

python src/[evaluate.py]

```

---

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

### ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
- **PyTorch 2.0+**: ëª¨ë¸ êµ¬í˜„ ë° í•™ìŠµ
- **torchvision**: ì‚¬ì „ í•™ìŠµëœ ResNet-152, ì´ë¯¸ì§€ ì „ì²˜ë¦¬

### ë°ì´í„° ì²˜ë¦¬
- **pycocotools**: COCO ë°ì´í„°ì…‹ ì²˜ë¦¬
- **NLTK**: ìì—°ì–´ í† í°í™” (punkt tokenizer)
- **Pillow**: ì´ë¯¸ì§€ ë¡œë”© ë° ë¦¬ì‚¬ì´ì¦ˆ

---

## í•µì‹¬ ê°œë…

### 1. Encoder-Decoder ì•„í‚¤í…ì²˜
- **ì¸ì½”ë” (CNN)**: ì´ë¯¸ì§€ â†’ ê³ ì • ê¸¸ì´ íŠ¹ì§• ë²¡í„° (256ì°¨ì›)ë¡œ ì••ì¶•
- **ë””ì½”ë” (LSTM)**: íŠ¹ì§• ë²¡í„° â†’ ë‹¨ì–´ ì‹œí€€ìŠ¤ë¡œ ë””ì½”ë”©


### 2. Teacher Forcing
í•™ìŠµ ì‹œ ì´ì „ ì˜ˆì¸¡ ë‹¨ì–´ê°€ ì•„ë‹Œ **ì •ë‹µ ë‹¨ì–´**ë¥¼ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ì†ë„ í–¥ìƒ:
```

# t=1: ì´ë¯¸ì§€ â†’ "A"

# t=2: "A" (ì •ë‹µ) â†’ "dog"

# t=3: "dog" (ì •ë‹µ) â†’ "playing"

```

### 3. Greedy Search (ì¶”ë¡  ì‹œ)
ê° ì‹œì ì—ì„œ **ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ë‹¨ì–´**ë¥¼ ì„ íƒí•˜ì—¬ ë¬¸ì¥ ìƒì„±:
```

for t in range(max_length):

logits = model(input_t)

word = argmax(logits)  # ìµœëŒ€ í™•ë¥  ë‹¨ì–´ ì„ íƒ

input_t+1 = embedding(word)

```

### 4. Pack Padded Sequence
ê°€ë³€ ê¸¸ì´ ìº¡ì…˜ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ íŒ¨ë”©ëœ ì‹œí€€ìŠ¤ë¥¼ ì••ì¶•:
```

packed = pack_padded_sequence(embeddings, lengths, batch_first=True)

```

---


## ğŸ“ í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
```

# src/[train.py]ì˜ config ìˆ˜ì •

config = {

'embedding_size': 256,      # ì„ë² ë”© ì°¨ì› (256, 512 ê¶Œì¥)

'hidden_size': 512,         # LSTM hidden size (512, 1024 ê¶Œì¥)

'num_layers': 1,            # LSTM ë ˆì´ì–´ ìˆ˜

'learning_rate': 0.001,     # í•™ìŠµë¥  (0.001~0.0001)

'batch_size': 128,          # ë°°ì¹˜ í¬ê¸° (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •)

}

```

### GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ
- `batch_size` ì¤„ì´ê¸° (128 â†’ 64 â†’ 32)
- `num_workers` ì¤„ì´ê¸° (2 â†’ 0)
- ì´ë¯¸ì§€ í¬ê¸° ì¤„ì´ê¸° (224 â†’ 196)

---

## ğŸ‘¤ ê°œë°œì

**Juyeong Park**  
- Email: [ju0korea@korea.ac.kr]
- GitHub: [@juyeong82]

